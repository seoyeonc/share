{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import transformers\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"meta-llama/Llama-2-7b-chat-hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/llm/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:655: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 1.62k/1.62k [00:00<00:00, 10.5MB/s]\n",
      "Downloading tokenizer.model: 100%|██████████| 500k/500k [00:00<00:00, 22.8MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 1.84M/1.84M [00:00<00:00, 1.90MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 414/414 [00:00<00:00, 3.42MB/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model,\n",
    "    use_auth_token=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 614/614 [00:00<00:00, 5.09MB/s]\n",
      "Downloading (…)fetensors.index.json: 100%|██████████| 26.8k/26.8k [00:00<00:00, 85.2MB/s]\n",
      "Downloading (…)of-00002.safetensors: 100%|██████████| 9.98G/9.98G [02:31<00:00, 65.7MB/s]\n",
      "Downloading (…)of-00002.safetensors: 100%|██████████| 3.50G/3.50G [00:53<00:00, 65.6MB/s]\n",
      "Downloading shards: 100%|██████████| 2/2 [03:26<00:00, 103.03s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]\n",
      "Downloading (…)neration_config.json: 100%|██████████| 188/188 [00:00<00:00, 1.87MB/s]\n"
     ]
    }
   ],
   "source": [
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    torch_dtype=torch.float32,\n",
    "    # device_map=\"gpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(x, max_length=200):\n",
    "    sequences = pipeline(\n",
    "        x,\n",
    "        do_sample=True,\n",
    "        top_k=10,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        max_length=max_length,\n",
    "    )\n",
    "\n",
    "    return sequences[0][\"generated_text\"].replace(x, \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I am also interested in watching movies. I enjoyed \"The Shawshank Redemption\" and \"The Godfather\". Can you recommend any other movies I might enjoy?\n",
      "\n",
      "I hope you can help me find some new shows and movies to watch!\n",
      "\n",
      "Sincerely,\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "print(gen('I liked \"Breaking Bad\" and \"Band of Brothers\". Do you have any recommendations of other shows I might like?\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. 예림 (AI Lab)\n",
      "2. 디지 (AI Lab)\n",
      "3. 크롬 (AI Lab)\n",
      "\n",
      "* 예림 (AI Lab)\n",
      "\n",
      "* 디지 (AI Lab)\n",
      "\n",
      "* 크롬 (AI Lab)\n",
      "\n",
      "* 예림 (AI Lab)\n",
      "\n",
      "* 디지 (AI Lab)\n",
      "\n",
      "* 크롬 (AI Lab)\n"
     ]
    }
   ],
   "source": [
    "print(gen(\"대한민국에서 유명한 인공지능 유튜버 3명만 나열해봐.\", 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---\n",
      "\n",
      "### 1. YouTube 빵형의 개발도상국 채널 알아?\n",
      "\n",
      "YouTube 빵형의 개발도상국 채널은 2023년 4월 기준으로 3000만 명 이상의 구독자를 보유하고 있습니다. 이 채널은 개발도상국 관련 테마의 콘텐츠를 제공하며, 채널 운영 및 콘텐츠 생성 분야에서 매우 높은 활동을 보이고 있습니다.\n",
      "| 채널 이름 | 구독자 수 |\n",
      "| --- | --- |\n",
      "| 빵형 | 3000만 명 이상 |\n",
      "| 빵형 TV | 1000만 명 이상 |\n",
      "| 빵형 북 | 500만 명 이상 |\n",
      "| 빵형 뉴스 | 300만 명 이상 |\n",
      "\n",
      "---\n",
      "\n",
      "위 표에 나타る 것처럼, YouTube 빵형의 개발도상국 채널은 3000만 명 이상의 구독자를 보유하고 있으며, 이 중 가장 인기�\n"
     ]
    }
   ],
   "source": [
    "print(gen(\"유튜브 빵형의 개발도상국 채널 알아?\", 500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단순 텍스트 생성 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/llm/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:655: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 776/776 [00:00<00:00, 6.47MB/s]\n",
      "Downloading tokenizer.model: 100%|██████████| 500k/500k [00:00<00:00, 21.6MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 1.84M/1.84M [00:00<00:00, 1.99MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 414/414 [00:00<00:00, 4.03MB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 609/609 [00:00<00:00, 5.85MB/s]\n",
      "Downloading (…)fetensors.index.json: 100%|██████████| 26.8k/26.8k [00:00<00:00, 66.2MB/s]\n",
      "Downloading (…)of-00002.safetensors: 100%|██████████| 9.98G/9.98G [01:33<00:00, 107MB/s]\n",
      "Downloading (…)of-00002.safetensors: 100%|██████████| 3.50G/3.50G [00:40<00:00, 87.2MB/s]\n",
      "Downloading shards: 100%|██████████| 2/2 [02:14<00:00, 67.04s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]\n",
      "Downloading (…)neration_config.json: 100%|██████████| 188/188 [00:00<00:00, 1.83MB/s]\n"
     ]
    }
   ],
   "source": [
    "model2 = \"meta-llama/Llama-2-7b-hf\"\n",
    "\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(\n",
    "    model2,\n",
    "    use_auth_token=True,\n",
    ")\n",
    "\n",
    "pipeline2 = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model2,\n",
    "    torch_dtype=torch.float32,\n",
    "    # device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen2(x, max_length=200):\n",
    "    sequences = pipeline2(\n",
    "        x,\n",
    "        do_sample=True,\n",
    "        top_k=10,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer2.eos_token_id,\n",
    "        max_length=max_length,\n",
    "    )\n",
    "\n",
    "    return sequences[0][\"generated_text\"].replace(x, \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have not watched any of those shows, but I do have a few recommendations.\n",
      "I would recommend \"The West Wing\" and \"The Newsroom\" (Sorkin's other shows).\n",
      "I would also recommend \"The Wire\" and \"Deadwood\".\n",
      "I'm currently watching \"The Wire\" and \"Deadwood\" (both on HBO).\n",
      "\"The Wire\" is a great show, and \"Deadwood\" is very good.\n",
      "\"The Wire\" is a great show, and \"Deadwood\" is very good. I'm currently watching \"The Wire\" and \"Deadwood\" (both on HBO).\n",
      "I'm not sure if you're a fan of \"Breaking Bad\" or not, but I'm not a\n"
     ]
    }
   ],
   "source": [
    "print(gen2('I liked \"Breaking Bad\" and \"Band of Brothers\". Do you have any recommendations of other shows I might like?\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
